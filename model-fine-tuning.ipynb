{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b97262f",
   "metadata": {},
   "source": [
    "### **Import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783cc655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chis Bogdan-Mihai\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5801f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chis Bogdan-Mihai\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Chis Bogdan-Mihai\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My heart pumps for you, my friend.\"\n",
      "\n",
      "The woman's voice quivered. \"We're both very happy. It's a really nice thing to be done.\"\n",
      "\n",
      "\"You were only kidding, sweetie. It's not like I'm telling you to keep quiet, but I don't want to hurt you.\"\n",
      "\n",
      "\"Okay… I'm gonna say it again. I'm gonna say it again. I'm gonna say it again.\"\n",
      "\n",
      "The woman's eyes narrowed, then narrowed again.\n",
      "\n",
      "\"And that's it. Just one more thing. You have to take care of your family as best as you can. And we'll be here in a minute, honey.\"\n",
      "\n",
      "\"I'm sure you'll be happy to hear it, but I think we need to find some way to get our family together.\"\n",
      "\n",
      "She took the phone from the woman's hand and started dialing again, this time by the woman's name, and then she started calling again.\n",
      "\n",
      "The woman's voice was too quiet, too focused, too clear, too soft.\n",
      "\n",
      "\"This is, uh, the last day of school. I think you're going to have to go to school, honey.\"\n",
      "\n",
      "\"No, you're not\n",
      "-----\n",
      "My heart pumps a little bit. I'm really happy with how our game has turned out and I think I feel a little more like I am back in the same situation I was at.\n",
      "\n",
      "\"This is something that I've been working on for a long time. I have been really excited to see what's out there but it's been really hard to get to where I am. It's been really hard to get there. I'm very happy with what we've been able to achieve this year. I think we are very happy with what we've achieved as well.\n",
      "\n",
      "\"It's been really hard to wait so long to get back to where we are. I'm very happy to be back and I think my teammates are very happy with the way we are. I'm happy to be back.\"\n",
      "-----\n",
      "My heart pumps out of my chest and I am about to burst out of the hospital,\" she said.\n",
      "\n",
      "Ms. Brown said she was happy to have found a doctor. \"I'm happy to have a place to live. I'm pleased to have a job in the United States and to be able to take care of my family,\" she said.\n",
      "\n",
      "\"I was so proud of my parents when they came here and I'm so excited to be here,\" she said.\n",
      "\n",
      "She said she will never forget her mother's words to her children, \"Don't let people tell you you have to fight for your dreams.\"\n",
      "\n",
      "\"I am a mother of three daughters. I'm a mother of 10 grandchildren,\" she said. \"I'm a mom of four daughters. I'm a mother of three daughters. I am a mother to a three-year-old in Illinois, a mother to a three-year-old in the Midwest and a mother to a 3-year-old in the Northeast,\" she said.\n",
      "\n",
      "\"My family has been so supportive and I'm so proud to be here. I'm proud to be a mom to a three-year-old in Wisconsin and to be able to take care of my family,\" she said.\n",
      "-----\n",
      "My heart pumps in my chest and I feel like there's no way I can do it. I tell myself I'm going to do it and I'm going to do it. What am I going to do? I'm going to go out there and do it. I'm going to do it.\n",
      "\n",
      "\"This is for you, and I'm going to do it. This is for all of us, and I'm going to do it. This is for all of the people that I've ever met. This is for all of the people that I've known, and I'm going to do it. This is for all of my friends, and I'm going to do it.\"\n",
      "\n",
      "Watch the video of the interview below:\n",
      "\n",
      "He made his first professional appearance on \"Late Night With Seth Meyers\" on Saturday, April 22, 2015.\n",
      "-----\n",
      "My heart pumps out.\n",
      "\n",
      "SINGLE SINGLE SINGLE SONG\n",
      "\n",
      "(Sleeppin' and singin' and singing) Don't let it get any worse.\n",
      "\n",
      "Don't let it get any worse.\n",
      "\n",
      "Don't let it get any worse.\n",
      "\n",
      "Don't let it get any worse.\n",
      "\n",
      "Don't let it get any worse.\n",
      "\n",
      "Don't let it get any worse.\n",
      "\n",
      "Don't let it get any worse.\n",
      "\n",
      "Don't let it get any worse.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any better.\n",
      "\n",
      "Don't let it get any\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "\n",
    "responses = generator(\"My heart pumps\", max_length=128, num_return_sequences=5)\n",
    "\n",
    "for response in responses:\n",
    "  print(response[\"generated_text\"])\n",
    "  print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6529d",
   "metadata": {},
   "source": [
    "## Verse I\n",
    "\n",
    "> *My heart pumps for you, my friend.*\n",
    "\n",
    "The woman's voice quivered.  \n",
    "> “We're both very happy. It's a really nice thing to be done.”\n",
    "\n",
    "> “You were only kidding, sweetie. It's not like I'm telling you to keep quiet, but I don't want to hurt you.”\n",
    "\n",
    "> “Okay… I'm gonna say it again. I'm gonna say it again. I'm gonna say it again.”\n",
    "\n",
    "The woman's eyes narrowed, then narrowed again.\n",
    "\n",
    "> “And that's it. Just one more thing. You have to take care of your family as best as you can. And we'll be here in a minute, honey.”\n",
    "\n",
    "> “I'm sure you'll be happy to hear it, but I think we need to find some way to get our family together.”\n",
    "\n",
    "She took the phone from the woman's hand and started dialing again, this time by the woman's name, and then she started calling again.\n",
    "\n",
    "The woman's voice was too quiet, too focused, too clear, too soft.\n",
    "\n",
    "> “This is, uh, the last day of school. I think you're going to have to go to school, honey.”\n",
    "\n",
    "> “No, you're not”\n",
    "\n",
    "---\n",
    "\n",
    "## Verse II\n",
    "\n",
    "> *My heart pumps a little bit.*\n",
    "\n",
    "I'm really happy with how our game has turned out, and I think I feel a little more like I am back in the same situation I was at.\n",
    "\n",
    "> “This is something that I've been working on for a long time.  \n",
    "> I have been really excited to see what's out there, but it's been really hard to get to where I am.  \n",
    "> It's been really hard to get there.  \n",
    "> I'm very happy with what we've been able to achieve this year.  \n",
    "> I think we are very happy with what we've achieved as well.\n",
    "\n",
    "> It's been really hard to wait so long to get back to where we are.  \n",
    "> I'm very happy to be back and I think my teammates are very happy with the way we are.  \n",
    "> I'm happy to be back.”\n",
    "\n",
    "---\n",
    "\n",
    "## Verse III\n",
    "\n",
    "> *My heart pumps out of my chest and I am about to burst out of the hospital,*” she said.\n",
    "\n",
    "Ms. Brown said she was happy to have found a doctor.\n",
    "\n",
    "> “I'm happy to have a place to live.  \n",
    "> I'm pleased to have a job in the United States and to be able to take care of my family.”\n",
    "\n",
    "> “I was so proud of my parents when they came here and I'm so excited to be here.”\n",
    "\n",
    "She said she will never forget her mother's words to her children:\n",
    "\n",
    "> “Don't let people tell you you have to fight for your dreams.”\n",
    "\n",
    "> “I am a mother of three daughters.  \n",
    "> I'm a mother of 10 grandchildren.  \n",
    "> I'm a mom of four daughters.  \n",
    "> I'm a mother of three daughters.  \n",
    "> I am a mother to a three-year-old in Illinois,  \n",
    "> a mother to a three-year-old in the Midwest,  \n",
    "> and a mother to a three-year-old in the Northeast.”\n",
    "\n",
    "> “My family has been so supportive and I'm so proud to be here.  \n",
    "> I'm proud to be a mom to a three-year-old in Wisconsin and to be able to take care of my family.”\n",
    "\n",
    "---\n",
    "\n",
    "## Verse IV\n",
    "\n",
    "> *My heart pumps in my chest and I feel like there's no way I can do it.*\n",
    "\n",
    "I tell myself I'm going to do it, and I'm going to do it.  \n",
    "What am I going to do?  \n",
    "I'm going to go out there and do it.  \n",
    "I'm going to do it.\n",
    "\n",
    "> “This is for you, and I'm going to do it.  \n",
    "> This is for all of us, and I'm going to do it.  \n",
    "> This is for all of the people that I've ever met.  \n",
    "> This is for all of the people that I've known, and I'm going to do it.  \n",
    "> This is for all of my friends, and I'm going to do it.”\n",
    "\n",
    "Watch the video of the interview below:\n",
    "\n",
    "He made his first professional appearance on *Late Night With Seth Meyers* on Saturday, April 22, 2015.\n",
    "\n",
    "---\n",
    "\n",
    "## Verse V\n",
    "\n",
    "> *My heart pumps out.*\n",
    "\n",
    "### SINGLE SINGLE SINGLE SONG\n",
    "\n",
    "*(Sleeppin' and singin' and singing)*  \n",
    "Don't let it get any worse.  \n",
    "Don't let it get any worse.  \n",
    "Don't let it get any worse.  \n",
    "Don't let it get any worse.  \n",
    "Don't let it get any worse.  \n",
    "Don't let it get any worse.  \n",
    "Don't let it get any worse.  \n",
    "Don't let it get any worse.\n",
    "\n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any better.  \n",
    "Don't let it get any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc358b",
   "metadata": {},
   "source": [
    "### **Import Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84186cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chis Bogdan-Mihai\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c118734",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the padding token to match the end-of-sequence (EOS) token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ce8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_poems(examples):\n",
    "    cleaned_poems = [\n",
    "        poem.replace(\"\\r\\n\", \"\\n\").strip() + tokenizer.eos_token\n",
    "        for poem in examples[\"Poem\"]\n",
    "    ]\n",
    "    return {\"text\": cleaned_poems}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
